# Системный промпт для оформления кода

## Введение

Данный системный промпт содержит рекомендации и правила оформления кода для проекта морфологического анализа текста. Следование этим правилам обеспечит читаемость, поддерживаемость и качество кода.

## Структура кода

### Организация файлов

```
project_root/
├── data/                 # Директория для входных и выходных данных
│   ├── input/            # Входные текстовые файлы
│   └── output/           # Результаты анализа
├── src/                  # Исходный код проекта
│   ├── __init__.py
│   ├── text_processor.py # Модуль для обработки текста
│   ├── morphology.py     # Модуль для морфологического анализа
│   ├── syllables.py      # Модуль для разделения на слоги
│   ├── trie.py           # Модуль для префиксного дерева
│   └── visualization.py  # Модуль для визуализации
├── tests/                # Тесты
│   ├── __init__.py
│   ├── test_text_processor.py
│   ├── test_morphology.py
│   ├── test_syllables.py
│   └── test_trie.py
├── main.py               # Главный скрипт для запуска программы
├── requirements.txt      # Зависимости проекта
└── README.md             # Описание проекта
```

### Импорты

Организуйте импорты в следующем порядке, с пустой строкой между группами:

1. Стандартные библиотеки Python
2. Библиотеки третьих сторон (внешние зависимости)
3. Локальные импорты (модули проекта)

```python
# Стандартные библиотеки
import os
import re
import sys
from collections import Counter

# Библиотеки третьих сторон
import numpy as np
import pymorphy2
import matplotlib.pyplot as plt

# Локальные импорты
from src.text_processor import TextProcessor
from src.trie import PrefixTree
```

## Стиль кодирования

### Общие правила (PEP 8)

1. **Отступы**: 4 пробела (не табуляция)
2. **Максимальная длина строки**: 79 символов
3. **Пустые строки**:
   - 2 пустые строки перед определением верхнеуровневых функций и классов
   - 1 пустая строка перед определением методов внутри класса
   - Используйте пустые строки для логического разделения блоков кода

### Именование

1. **Файлы и модули**: короткие имена в нижнем регистре, с подчеркиванием если необходимо: `text_processor.py`
2. **Классы**: CamelCase (PascalCase): `TextProcessor`, `PrefixTree`
3. **Функции и методы**: snake_case: `process_text()`, `build_trie()`
4. **Переменные**: snake_case: `word_count`, `processed_text`
5. **Константы**: UPPER_CASE_WITH_UNDERSCORES: `MAX_WORD_LENGTH`, `DEFAULT_LANGUAGE`

### Примеры именования

```python
# Плохо
def Analyze(txt):
    WrdCount = len(txt.split())
    return WrdCount

# Хорошо
def analyze_text(text):
    word_count = len(text.split())
    return word_count
```

## Документация кода

### Документация модуля

Каждый модуль должен начинаться с докстринга, описывающего его назначение:

```python
"""
Модуль для морфологического анализа текста.

Этот модуль предоставляет функции для определения морфологических 
характеристик слов в тексте и снятия омонимии на основе контекста.
"""
```

### Документация классов

```python
class MorphologicalAnalyzer:
    """
    Класс для выполнения морфологического анализа текста.
    
    Класс использует библиотеку pymorphy2 для определения грамматических
    характеристик слов и содержит методы для снятия омонимии.
    
    Attributes:
        analyzer: Экземпляр морфологического анализатора pymorphy2
        language (str): Язык анализируемого текста (по умолчанию 'ru')
    """
```

### Документация функций и методов

```python
def split_into_syllables(word: str) -> List[str]:
    """
    Разделяет слово на слоги согласно правилам русского языка.
    
    Args:
        word: Слово для разделения
        
    Returns:
        Список слогов
        
    Examples:
        >>> split_into_syllables("молоко")
        ['мо', 'ло', 'ко']
    """
```

## Типизация (Type Hints)

Используйте аннотации типов для всех функций и методов:

```python
from typing import Dict, List, Optional, Tuple, Union

def process_text(text: str, normalize: bool = True) -> List[str]:
    """Обработка текста и разделение на токены."""
    pass

def analyze_word(word: str) -> Dict[str, Union[str, List[str]]]:
    """Морфологический анализ слова."""
    pass

class PrefixTree:
    def insert(self, key: List[str], value: Dict) -> None:
        """Вставка значения в дерево по ключу."""
        pass
    
    def search(self, key: List[str]) -> Optional[Dict]:
        """Поиск значения по ключу."""
        pass
```

## Форматирование кода

### Комментарии

1. **Общие правила**:
   - Комментарии должны быть краткими и по существу
   - Комментарии должны быть актуальными и соответствовать коду
   - Избегайте очевидных комментариев

2. **Блочные комментарии**:
   ```python
   # Этот блок кода реализует алгоритм разделения слова на слоги
   # на основе правил, описанных в статье "Фонетическая структура
   # русского слова" (Автор, 2020)
   ```

3. **Встроенные комментарии**:
   ```python
   vowel_count = sum(1 for char in word if char in VOWELS)  # Подсчет гласных
   ```

### Строки документации

1. **Формат докстрингов**: Следуйте формату Google или NumPy для докстрингов

2. **Пример Google-стиля**:
   ```python
   def calculate_statistics(words: List[str]) -> Dict[str, int]:
       """Рассчитывает статистику для набора слов.
       
       Args:
           words: Список слов для анализа
           
       Returns:
           Словарь с различными статистическими показателями
           
       Raises:
           ValueError: Если список слов пуст
       """
   ```

## Рекомендации по написанию кода

### DRY (Don't Repeat Yourself)

Избегайте дублирования кода. Выделяйте повторяющиеся операции в отдельные функции.

```python
# Плохо
def process_file1(filename):
    with open(filename, 'r', encoding='utf-8') as f:
        text = f.read()
    words = text.split()
    return [word.lower() for word in words]

def process_file2(filename):
    with open(filename, 'r', encoding='utf-8') as f:
        text = f.read()
    words = text.split()
    return [word.lower() for word in words]

# Хорошо
def read_and_tokenize(filename):
    with open(filename, 'r', encoding='utf-8') as f:
        text = f.read()
    words = text.split()
    return [word.lower() for word in words]

def process_file1(filename):
    return read_and_tokenize(filename)

def process_file2(filename):
    return read_and_tokenize(filename)
```

### Обработка ошибок

Используйте механизм исключений для обработки ошибок:

```python
def read_text_file(filename: str) -> str:
    """
    Читает текст из файла.
    
    Args:
        filename: Путь к файлу
        
    Returns:
        Содержимое файла
        
    Raises:
        FileNotFoundError: Если файл не найден
        UnicodeDecodeError: Если файл не может быть декодирован как UTF-8
    """
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        raise FileNotFoundError(f"Файл {filename} не найден")
    except UnicodeDecodeError:
        raise UnicodeDecodeError(f"Файл {filename} не может быть декодирован как UTF-8")
```

### Магические числа и строки

Избегайте "магических" чисел и строк в коде. Вместо этого используйте константы:

```python
# Плохо
if len(word) > 15:
    word = word[:15]

# Хорошо
MAX_WORD_LENGTH = 15
if len(word) > MAX_WORD_LENGTH:
    word = word[:MAX_WORD_LENGTH]
```

## Примеры кода

### Правильно оформленный класс

```python
from typing import Dict, List, Optional
import pymorphy2


class MorphologicalAnalyzer:
    """
    Класс для морфологического анализа текста.
    
    Attributes:
        analyzer: Экземпляр морфологического анализатора
        language (str): Язык для анализа
    """
    
    def __init__(self, language: str = 'ru'):
        """
        Инициализирует анализатор.
        
        Args:
            language: Код языка (по умолчанию 'ru' - русский)
        """
        self.language = language
        self.analyzer = pymorphy2.MorphAnalyzer()
        
    def analyze_word(self, word: str) -> Dict[str, str]:
        """
        Выполняет морфологический анализ слова.
        
        Args:
            word: Слово для анализа
            
        Returns:
            Словарь с морфологическими характеристиками
        """
        parsed = self.analyzer.parse(word)[0]
        
        return {
            'normal_form': parsed.normal_form,
            'pos': parsed.tag.POS or 'UNKNOWN',
            'gender': parsed.tag.gender or 'NA',
            'number': parsed.tag.number or 'NA',
            'case': parsed.tag.case or 'NA',
        }
    
    def analyze_text(self, text: str) -> List[Dict[str, str]]:
        """
        Анализирует весь текст, разбивая его на слова.
        
        Args:
            text: Текст для анализа
            
        Returns:
            Список словарей с морфологическими характеристиками для каждого слова
        """
        words = text.split()
        return [self.analyze_word(word) for word in words]
    
    def resolve_homonymy(self, word: str, context: List[str]) -> Dict[str, str]:
        """
        Выполняет снятие омонимии на основе контекста.
        
        Args:
            word: Анализируемое слово
            context: Список слов контекста
            
        Returns:
            Словарь с наиболее вероятными морфологическими характеристиками
        """
        # Реализация снятия омонимии...
        pass
```

## Заключение

Следование этому системному промпту поможет создать чистый, понятный и поддерживаемый код. Помните, что хороший код - это не только тот, который выполняет поставленную задачу, но и тот, который легко читать, понимать и изменять.
